{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes de Videojuegos con PyTorch\n",
    "\n",
    "Este notebook implementa un sistema completo de clasificación de imágenes de videojuegos utilizando redes neuronales convolucionales (CNN) con PyTorch.\n",
    "\n",
    "## Dataset\n",
    "Utilizamos el dataset **gameplay-images** de Kaggle que contiene imágenes de diferentes géneros de videojuegos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalación de Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar las librerías necesarias (descomentar si es necesario)\n",
    "# !pip install kagglehub\n",
    "# !pip install torch torchvision torchaudio matplotlib scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import os\n",
    "from PIL import Image\n",
    "import kagglehub\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuración de device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descarga y Preparación del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iniciando descarga del dataset de Kaggle...\")\n",
    "# handle del dataset: aditmagotra/gameplay-images\n",
    "try:\n",
    "    path = kagglehub.dataset_download(\"aditmagotra/gameplay-images\")\n",
    "    \n",
    "    # La ruta devuelta por kagglehub apunta a la carpeta principal del dataset\n",
    "    # En este caso, el contenido \"gameplay-images\" está dentro de esta ruta.\n",
    "    # Necesitamos encontrar la carpeta donde están las subcarpetas de clase.\n",
    "    \n",
    "    # Buscamos la subcarpeta que contiene las 10 clases\n",
    "    # La estructura de la descarga suele ser: path/gameplay-images/...\n",
    "    data_dir = os.path.join(path, 'gameplay-images')\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        # Si la estructura es plana (solo los archivos dentro de 'path')\n",
    "        data_dir = path\n",
    "        \n",
    "    print(f\"Descarga completada. Directorio base de datos: {data_dir}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Falló la descarga de Kaggle. Asegúrate de estar autenticado (kaggle.json).\")\n",
    "    print(f\"Error detallado: {e}\")\n",
    "    # Usar una ruta local para continuar el script si la descarga manual es necesaria\n",
    "    data_dir = './gameplay-images'\n",
    "    if not os.path.exists(data_dir):\n",
    "        raise FileNotFoundError(f\"No se encontró el directorio de datos: {data_dir}. ¡Asegúrate de descargarlo manualmente si la descarga en línea falló!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verificación y Conteo de Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener lista de clases (solo directorios)\n",
    "classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "classes.sort() \n",
    "print(f\"\\nClases encontradas: {classes}\")\n",
    "\n",
    "# Contar imágenes por clase\n",
    "print(\"\\nConteo de imágenes por clase:\")\n",
    "class_counts = {}\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    count = len(os.listdir(class_path))\n",
    "    class_counts[class_name] = count\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "# Guardar nombres de clases y número total de clases\n",
    "class_names = classes\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"\\nNúmero total de clases: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualización de la Distribución de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de barras de la distribución de clases\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color='skyblue', edgecolor='navy')\n",
    "plt.xlabel('Clase', fontsize=12)\n",
    "plt.ylabel('Número de Imágenes', fontsize=12)\n",
    "plt.title('Distribución de Imágenes por Clase', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualización de Imágenes de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar algunas imágenes de ejemplo de cada clase\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, class_name in enumerate(class_names[:10]):\n",
    "    class_path = os.path.join(data_dir, class_name)\n",
    "    images = os.listdir(class_path)\n",
    "    if images:\n",
    "        img_path = os.path.join(class_path, images[0])\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(class_name, fontsize=10, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Definición de Transformaciones y Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "# Transformaciones con data augmentation para entrenamiento\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformaciones para validación (sin augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Cargar dataset completo\n",
    "full_dataset = datasets.ImageFolder(data_dir)\n",
    "\n",
    "# Dividir en train y validation\n",
    "dataset_size = len(full_dataset)\n",
    "val_size = int(VAL_SPLIT * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Aplicar transformaciones\n",
    "train_dataset.dataset.transform = train_transforms\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset cargado:\")\n",
    "print(f\"  - Total de imágenes: {dataset_size}\")\n",
    "print(f\"  - Imágenes de entrenamiento: {train_size}\")\n",
    "print(f\"  - Imágenes de validación: {val_size}\")\n",
    "print(f\"  - Número de clases: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Definición del Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideogameCNN(nn.Module):\n",
    "    \"\"\"Red neuronal convolucional personalizada para clasificación de imágenes de videojuegos.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10, dropout_rate=0.5):\n",
    "        super(VideogameCNN, self).__init__()\n",
    "        \n",
    "        # Bloque convolucional 1\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Bloque convolucional 2\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Bloque convolucional 3\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Bloque convolucional 4\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Capas fully connected\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.fc1 = nn.Linear(256 * 7 * 7, 512)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Bloque 1\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Bloque 2\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Bloque 3\n",
    "        x = torch.relu(self.bn5(self.conv5(x)))\n",
    "        x = torch.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Bloque 4\n",
    "        x = torch.relu(self.bn7(self.conv7(x)))\n",
    "        x = torch.relu(self.bn8(self.conv8(x)))\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        # Adaptive pooling y flatten\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Capas fully connected\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Crear modelo\n",
    "model = VideogameCNN(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# Contar parámetros\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModelo creado:\")\n",
    "print(f\"  - Parámetros totales: {total_params:,}\")\n",
    "print(f\"  - Parámetros entrenables: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Configuración del Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Loss, optimizer y scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "print(f\"Configuración de entrenamiento:\")\n",
    "print(f\"  - Épocas: {NUM_EPOCHS}\")\n",
    "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Optimizer: Adam\")\n",
    "print(f\"  - Loss function: CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Función de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, \n",
    "                device, num_epochs=25):\n",
    "    \"\"\"Entrena el modelo y retorna el historial.\"\"\"\n",
    "    \n",
    "    import time\n",
    "    import copy\n",
    "    \n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Fase de entrenamiento\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc='Entrenamiento'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        \n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc.item())\n",
    "        \n",
    "        print(f'Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}')\n",
    "        \n",
    "        # Fase de validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc='Validación'):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc.item())\n",
    "        \n",
    "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Guardar mejor modelo\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            print(f'✓ Mejor modelo guardado con accuracy: {val_acc:.4f}')\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Entrenamiento completado en {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Mejor precisión en validación: {best_acc:.4f}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    num_epochs=NUM_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualización del Historial de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de precisión y pérdida\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Precisión\n",
    "axes[0].plot(history['train_acc'], label='Entrenamiento', marker='o', linewidth=2)\n",
    "axes[0].plot(history['val_acc'], label='Validación', marker='s', linewidth=2)\n",
    "axes[0].set_title('Precisión del Modelo', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Época', fontsize=12)\n",
    "axes[0].set_ylabel('Precisión', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Pérdida\n",
    "axes[1].plot(history['train_loss'], label='Entrenamiento', marker='o', linewidth=2)\n",
    "axes[1].plot(history['val_loss'], label='Validación', marker='s', linewidth=2)\n",
    "axes[1].set_title('Pérdida del Modelo', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Época', fontsize=12)\n",
    "axes[1].set_ylabel('Pérdida', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"Evaluando modelo...\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(val_loader, desc='Evaluación'):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'\\nAccuracy: {accuracy:.4f}')\n",
    "\n",
    "# Reporte de clasificación\n",
    "print('\\nReporte de Clasificación:')\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Número de predicciones'})\n",
    "plt.title('Matriz de Confusión', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicción', fontsize=12)\n",
    "plt.ylabel('Verdadero', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Guardar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model_save_path = '../models/videojuegos_classifier_final.pth'\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_names': class_names,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'model_type': 'cnn',\n",
    "    'accuracy': accuracy,\n",
    "    'image_size': IMAGE_SIZE\n",
    "}, model_save_path)\n",
    "\n",
    "print(f'Modelo guardado en: {model_save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Predicción en Nuevas Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path, class_names, device, transform):\n",
    "    \"\"\"Realiza una predicción sobre una imagen.\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "    \n",
    "    top5_prob, top5_catid = torch.topk(probabilities, min(5, len(class_names)))\n",
    "    \n",
    "    return {\n",
    "        'class': class_names[top5_catid[0]],\n",
    "        'confidence': float(top5_prob[0]),\n",
    "        'top5': [\n",
    "            {'class': class_names[cat_id], 'probability': float(prob)}\n",
    "            for prob, cat_id in zip(top5_prob, top5_catid)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Ejemplo de predicción (ajusta la ruta a una imagen real)\n",
    "# test_image_path = 'ruta/a/tu/imagen.jpg'\n",
    "# prediction = predict_image(model, test_image_path, class_names, device, val_transforms)\n",
    "# print(f\"Predicción: {prediction['class']} (Confianza: {prediction['confidence']*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Conclusiones\n",
    "\n",
    "En este notebook hemos:\n",
    "1. Descargado y preparado el dataset de imágenes de videojuegos desde Kaggle\n",
    "2. Implementado una red neuronal convolucional personalizada\n",
    "3. Entrenado el modelo con data augmentation\n",
    "4. Evaluado el rendimiento con métricas detalladas\n",
    "5. Guardado el modelo para uso futuro\n",
    "\n",
    "### Próximos Pasos\n",
    "- Experimentar con diferentes arquitecturas (ResNet, EfficientNet)\n",
    "- Ajustar hiperparámetros para mejorar el rendimiento\n",
    "- Implementar técnicas de regularización adicionales\n",
    "- Desplegar el modelo en producción"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
